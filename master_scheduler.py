import pandas as pd
import numpy as np
import os
import sys

# ==========================================
# 1. å…¨å±€å˜é‡é¢„å…ˆåˆå§‹åŒ–
# ==========================================
run_tactical_analysis = None
set_tactical_api = None
run_grenade_analysis = None
set_grenade_api = None
process_dem_file = None
get_eco_df = None
extract_specified_player_data_wrapper = None

print("ðŸ“¦ [System] æ­£åœ¨åŠ è½½æ¨¡å—...")

# ==========================================
# 2. å®‰å…¨å¯¼å…¥å­æ¨¡å—
# ==========================================
try:
    from data_analysis import run_tactical_analysis, setAPI as set_tactical_api
except Exception as e: print(f"   âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½æˆ˜æœ¯æ¨¡å—: {e}")

try:
    from createTexts import run_grenade_analysis, setAPI_KEY as set_grenade_api
except Exception as e: print(f"   âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½é“å…·æ¨¡å—: {e}")

try:
    from final_kill import process_dem_file
except Exception as e: print(f"   âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½å‡»æ€æ¨¡å—: {e}")

try:
    from eco_and_round import get_events_df as get_eco_df
except Exception as e: print(f"   âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½ç»æµŽæ¨¡å—: {e}")

try:
    from pretreatment import extract_specified_player_data_wrapper
except Exception as e: print(f"   âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½é¢„å¤„ç†æ¨¡å—: {e}")


# ==========================================
# 3. è°ƒåº¦å™¨ç±»å®šä¹‰
# ==========================================
class MasterScheduler:
    def __init__(self, demo_path, api_key):
        self.demo_path = demo_path
        self.api_key = api_key
        
        self.base_name = os.path.splitext(os.path.basename(demo_path))[0]
        self.output_dir = os.path.join("data", self.base_name)
        os.makedirs(self.output_dir, exist_ok=True)
        self.raw_data_path = os.path.join(self.output_dir, "1_raw_data.csv")
        
        self.round_global_offsets = {} 
        self.round_start_ticks = {}
        
        self._distribute_api_key()

    def _distribute_api_key(self):
        print(f"ðŸ”‘ [System] æ­£åœ¨åˆ†å‘ API Key...")
        if set_tactical_api: set_tactical_api(self.api_key)
        if set_grenade_api: set_grenade_api(self.api_key)
        os.environ["DASHSCOPE_API_KEY"] = self.api_key
        os.environ["OPENAI_API_KEY"] = self.api_key

    def _calculate_offsets(self):
        if not os.path.exists(self.raw_data_path): return
        try:
            df = pd.read_csv(self.raw_data_path, usecols=['round_num', 'second', 'tick'])
            self.round_start_ticks = df.groupby('round_num')['tick'].min().to_dict()
            rounds = sorted(df['round_num'].unique())
            running_time = 0.0
            is_second_half = False
            for r_num in rounds:
                if r_num == 13 and not is_second_half:
                    running_time = 0.0
                    is_second_half = True
                self.round_global_offsets[r_num] = running_time
                max_sec = df[df['round_num'] == r_num]['second'].max()
                running_time += max_sec
            print(f"âœ… [System] å·²å»ºç«‹æˆ˜æœ¯æ—¶é—´åŸºå‡† (è¦†ç›– {len(rounds)} ä¸ªå›žåˆ)")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è®¡ç®—æ—¶é—´åç§»: {e}")

    def step1_pretreatment(self):
        if os.path.exists(self.raw_data_path):
            print("âœ… [Step 1] åŸºç¡€æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡æå–ã€‚")
            self._calculate_offsets()
            return True

        if not extract_specified_player_data_wrapper:
            print("âŒ é”™è¯¯ï¼šç¼ºå°‘é¢„å¤„ç†æ¨¡å—ä¸”æ— ç¼“å­˜æ•°æ®ã€‚")
            return False

        print("ðŸ”„ [Step 1] æå–åŸºç¡€æ•°æ®...")
        try:
            extract_specified_player_data_wrapper(self.demo_path, self.raw_data_path)
            self._calculate_offsets()
            return True
        except Exception as e:
            print(f"âŒ é¢„å¤„ç†æ‰§è¡Œå¤±è´¥: {e}")
            return False

    def _align_to_tactical_standard(self, df, module_type):
        if df.empty: return df
        
        # 1. æˆ˜æœ¯æ¨¡å—: å·²ç»æ˜¯å‡€æ—¶é—´ï¼Œæ— éœ€è½¬æ¢
        if module_type == 'tactical': return df
        
        # 2. å‡»æ€æ¨¡å—: å·²ç»æ˜¯ç›¸å¯¹æ—¶é—´ (Relative)ï¼Œåªéœ€åŠ  Offset
        if module_type == 'kill':
            def fix_relative(row):
                r = row['round_num']
                rel_t = row['start_time']
                offset = self.round_global_offsets.get(r, 0.0)
                return offset + rel_t
            df['start_time'] = df.apply(fix_relative, axis=1)
            return df
            
        # 3. é“å…· & ç»æµŽ: æ˜¯ç»å¯¹æ—¶é—´ (Absolute)ï¼Œå¿…é¡»å…ˆå‡åŽ» RoundStartï¼Œå†åŠ  Offset
        if module_type in ['grenade', 'economy']:
            def fix_absolute(row):
                r = row['round_num']
                abs_t_sec = row['start_time'] # è¿™é‡Œæ˜¯ç»å¯¹æ—¶é—´ (ç§’)
                
                # èŽ·å–è¯¥å›žåˆçš„ç»å¯¹å¼€å§‹æ—¶é—´ (ç§’)
                start_tick = self.round_start_ticks.get(r)
                rel_t = 0.0
                if start_tick:
                    base_sec = start_tick / 128.0
                    # è®¡ç®—ç›¸å¯¹æ—¶é—´ (åŽ»æŽ‰äº†çƒ­èº«/æš‚åœ)
                    rel_t = max(0.0, abs_t_sec - base_sec)
                
                # åŠ ä¸Šå…¨å±€åç§»ï¼Œå¯¹é½åˆ°æˆ˜æœ¯æ—¶é—´è½´
                offset = self.round_global_offsets.get(r, 0.0)
                return offset + rel_t

            df['start_time'] = df.apply(fix_absolute, axis=1)
            return df
            
        return df

    def step2_collect_all_modules(self):
        all_dfs = []
        print("\nðŸš€ [Step 2] å¹¶è¡Œè°ƒç”¨å­æ¨¡å—...")

        # A. æˆ˜æœ¯
        t1 = os.path.join(self.output_dir, "tactical_gen_cache.csv")
        df_tact = pd.DataFrame()
        if os.path.exists(t1):
            print(f"   >>> æˆ˜æœ¯æ¨¡å—: è¯»å–ç¼“å­˜")
            df_tact = pd.read_csv(t1)
        elif run_tactical_analysis:
            print(f"   >>> æˆ˜æœ¯æ¨¡å—: è¿è¡Œç”Ÿæˆ...")
            try: df_tact = run_tactical_analysis(self.raw_data_path, self.output_dir)
            except: pass
        if not df_tact.empty:
            df_tact['module'] = 'tactical'
            all_dfs.append(df_tact)

        # B. å‡»æ€
        k1 = os.path.join(self.output_dir, "kill_gen_cache.csv")
        if os.path.exists(k1):
            print("   >>> å‡»æ€æ¨¡å—: è¯»å–ç¼“å­˜")
            df = pd.read_csv(k1)
            df['module'] = 'kill'
            df = self._align_to_tactical_standard(df, 'kill')
            all_dfs.append(df)
        elif process_dem_file:
            print("   >>> å‡»æ€æ¨¡å—: è¿è¡Œç”Ÿæˆ...")
            try:
                df = process_dem_file(self.demo_path, self.api_key, verbose=False)
                if not df.empty:
                    df['module'] = 'kill'
                    df = self._align_to_tactical_standard(df, 'kill')
                    all_dfs.append(df)
            except Exception as e: print(f"Error Kill: {e}")

        # C. é“å…·
        g1 = os.path.join(self.output_dir, "grenade_gen_cache.csv")
        if os.path.exists(g1):
            print("   >>> é“å…·æ¨¡å—: è¯»å–ç¼“å­˜")
            df = pd.read_csv(g1)
            df['module'] = 'grenade'
            df = self._align_to_tactical_standard(df, 'grenade')
            all_dfs.append(df)
        elif run_grenade_analysis:
            print("   >>> é“å…·æ¨¡å—: è¿è¡Œç”Ÿæˆ...")
            try:
                df = run_grenade_analysis(self.demo_path)
                if not df.empty:
                    df['module'] = 'grenade'
                    df = self._align_to_tactical_standard(df, 'grenade')
                    all_dfs.append(df)
            except: pass

        # D. ç»æµŽ
        e1 = os.path.join(self.output_dir, "economy_gen_cache.csv")
        if os.path.exists(e1):
            print("   >>> ç»æµŽæ¨¡å—: è¯»å–ç¼“å­˜")
            df = pd.read_csv(e1)
            df['module'] = 'economy'
            df = self._align_to_tactical_standard(df, 'economy') 
            all_dfs.append(df)
        elif get_eco_df:
            print("   >>> ç»æµŽæ¨¡å—: è¿è¡Œç”Ÿæˆ...")
            try:
                df = get_eco_df(self.demo_path, enable_llm=True)
                if not df.empty:
                    df['module'] = 'economy'
                    df = self._align_to_tactical_standard(df, 'economy')
                    all_dfs.append(df)
            except: pass

        return all_dfs

    def step3_merge(self, all_dfs):
        if not all_dfs: return pd.DataFrame()
        
        core_cols = ['event_id', 'round_num', 'start_time', 'priority', 
                     'short_text_neutral', 'medium_text_neutral', 'long_text_neutral', 'module']
        
        cleaned = []
        for df in all_dfs:
            temp = df.copy()
            for c in core_cols:
                if c not in temp.columns: temp[c] = ""
            cleaned.append(temp[core_cols])
            
        final_df = pd.concat(cleaned, ignore_index=True)
        final_df['start_time'] = pd.to_numeric(final_df['start_time'], errors='coerce').fillna(0)
        final_df['priority'] = pd.to_numeric(final_df['priority'], errors='coerce').fillna(1)
        final_df['round_num'] = pd.to_numeric(final_df['round_num'], errors='coerce').fillna(0)

        # ç»æµŽè§£è¯´ä¼˜å…ˆçº§æå‡
        mask_eco = final_df['module'] == 'economy'
        final_df.loc[mask_eco, 'priority'] += 8 

        return final_df.sort_values(by=['round_num', 'start_time', 'priority'], ascending=[True, True, False])

    def step5_schedule_and_output(self, df):
        print("âš”ï¸ [Step 4] æ™ºèƒ½æŽ’æœŸ v3.1 (ä¸­é•¿æ–‡æœ¬ä¼˜å…ˆ + å¼ºåˆ¶æ’é˜Ÿ)...")
        schedule = []
        global_cursor = 0.0
        
        half_break_index = None
        is_second_half_started = False
        
        df = df.sort_values(by=['round_num', 'start_time', 'priority'], ascending=[True, True, False])
        
        for _, row in df.iterrows():
            r_num = row['round_num']
            start_t = row['start_time']
            prio = row['priority']
            module = row['module']
            
            # === ðŸ”¥ ä¿®æ”¹ç‚¹ï¼šåªå– Medium æˆ– Long ===
            text = str(row.get('medium_text_neutral', '')).strip()
            if not text or text.lower() in ['nan', 'none', '']:
                text = str(row.get('long_text_neutral', '')).strip()
            
            if not text or text.lower() in ['nan', 'none', '']: 
                continue
            # =======================================

            if r_num >= 13 and not is_second_half_started:
                is_second_half_started = True
                half_break_index = len(schedule)
                if start_t < global_cursor: global_cursor = 0.0

            text = text.replace("çŸ­ç‰ˆ", "").replace("ä¸­ç‰ˆ", "").replace("é•¿ç‰ˆ", "").replace("---", "").strip()
            if not text: continue

            # åŠ¨æ€æ—¶é•¿
            est_duration = len(text) / 5.0
            dur = max(2.5, min(est_duration, 10.0)) 
            if module == 'grenade': dur = min(dur, 3.0) 

            # ðŸš€ å¼ºåˆ¶æ’é˜Ÿé€»è¾‘
            final_start = start_t
            
            if module == 'tactical':
                if start_t > global_cursor + 8.0:
                    final_start = start_t 
                else:
                    if global_cursor - final_start < 25.0: 
                        final_start = global_cursor
                    else:
                        continue 
            else:
                if final_start < global_cursor:
                     if prio >= 6: 
                         final_start = global_cursor
                     else:
                         if global_cursor - final_start < 3.0:
                             final_start = global_cursor
                         else:
                             continue
            
            final_end = final_start + dur
            schedule.append({
                'æ—¶é—´èŒƒå›´': f"{final_start:.1f}-{final_end:.1f}s",
                'è§£è¯´æ–‡æœ¬': text
            })
            global_cursor = final_end
            
        if half_break_index is None: half_break_index = len(schedule)
        return pd.DataFrame(schedule), half_break_index

    def run(self):
        if not self.step1_pretreatment(): return

        all_dfs = self.step2_collect_all_modules()
        merged = self.step3_merge(all_dfs)
        
        if merged.empty:
            print("âŒ é”™è¯¯ï¼šæ— æ•°æ®ç”Ÿæˆ")
            return
            
        final_sch, split_idx = self.step5_schedule_and_output(merged)
        
        sch1 = final_sch.iloc[:split_idx]
        sch2 = final_sch.iloc[split_idx:]
        
        p1 = os.path.join(self.output_dir, "final_upper_half.csv")
        p2 = os.path.join(self.output_dir, "final_lower_half.csv")
        
        sch1.to_csv(p1, index=False, encoding="utf-8-sig")
        sch2.to_csv(p2, index=False, encoding="utf-8-sig")
        
        print(f"\nâœ… å…¨éƒ¨å®Œæˆ! \nä¸ŠåŠåœº: {p1} ({len(sch1)}æ¡)\nä¸‹åŠåœº: {p2} ({len(sch2)}æ¡)")