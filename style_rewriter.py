import pandas as pd
import os
import json
import glob
import concurrent.futures
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ================= é…ç½®åŒºåŸŸ =================
MY_API_KEY = os.getenv("DASHSCOPE_API_KEY") 
MODEL_NAME = "qwen3-max" 
BLACKLIST_KEYWORDS = [
    "æ‘”æ­»", "è‡ªæ€", "æœªçŸ¥", "world", "World", "Trigger", "entity", "Bot", "BOT"
]
# ===========================================

def get_machine_style_prompt_with_timing(events_batch):
    events_str = json.dumps(events_batch, ensure_ascii=False)
    
    return f"""
ä½ ç°åœ¨æ˜¯CS2çŸ¥åä¸»æ’­â€œç©æœºå™¨â€ï¼ˆMachineï¼‰ã€‚
è¯·å°†ä»¥ä¸‹ã€è§£è¯´åŸæ–‡ã€‘é‡å†™ä¸ºã€ç©æœºå™¨ç›´æ’­é£æ ¼ã€‘ï¼Œå¹¶**ä¸¥æ ¼éµå®ˆæ—¶é•¿é™åˆ¶**ã€‚

ã€äººè®¾è¦æ±‚ã€‘
1. **é£æ ¼**ï¼šæåº¦å£è¯­åŒ–ã€é˜´é˜³æ€ªæ°”ã€é€ æ¢—å¤§å¸ˆã€‚
   - å¸¸ç”¨è¯ï¼šç™½ç»™ã€è¿™å°±ç»™å•¦ï¼Ÿã€é¡¶çº§ç†è§£ã€åªæœ‰å¹²æ‹‰ã€æ²¡ä»€ä¹ˆå¥½è¯´çš„ã€ä¹Ÿå°±æ˜¯ä¸ªdonkã€‚
   - ç§°å‘¼ï¼šFlameZ=ç«ä»”, ZywOo=è½½ç‰©/è–¯è–¯, donk=å°å­©/é‚£å°å­©, sh1ro=è™½ç„¶, mezii=æ¢…è¥¿ã€‚
2. **æ‹’ç»ç”µæŠ¥é£**ï¼šè™½ç„¶æœ‰æ—¶é•¿é™åˆ¶ï¼Œä½†ä¸è¦å†™æˆâ€œTè¿›æ”»Aâ€ï¼Œè¦è¯´â€œTè¿™å°±ç›´æ¥å¹²æ‹‰AåŒºäº†å•Šâ€ã€‚
   - å®å¯è¯­é€Ÿå¿«ä¸€ç‚¹ï¼ˆå­—æ•°ç¨å¤šï¼‰ï¼Œä¹Ÿä¸è¦è¯´è¯åªè¯´ä¸€åŠï¼
3. **æªæ¢°é»‘è¯**ï¼šUSP=å°æ‰‹æª, Glock=æ ¼æ´›å…‹/æ»‹æ°´æª, AWP=å¤§ç‹™, SSG08=é¸Ÿç‹™, Deagle=æ²™é¹°ã€‚
4. **è¿‡æ»¤**ï¼šé‡åˆ°â€œæ‘”æ­»/è‡ªæ€â€ç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸² ""ã€‚

ã€è¾“å…¥æ•°æ®ã€‘(JSON):
{events_str}

ã€è¾“å‡ºæ ¼å¼ã€‘(çº¯JSONåˆ—è¡¨ï¼ŒåªåŒ…å«é‡å†™åçš„æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œé¡ºåºå¯¹åº”):
["é‡å†™åæ–‡æœ¬1", "é‡å†™åæ–‡æœ¬2", ""]
"""

def process_batch(client, batch_df):
    events_batch = []
    for _, row in batch_df.iterrows():
        # ä¼°ç®—æ—¶é•¿
        t_range = str(row['æ—¶é—´èŒƒå›´']).replace('s', '').split('-')
        duration = 4.0
        try: duration = float(t_range[1]) - float(t_range[0])
        except: pass
        
        events_batch.append({
            "text": row['è§£è¯´æ–‡æœ¬'],
            "duration": round(duration, 1)
        })
        
    prompt = get_machine_style_prompt_with_timing(events_batch)
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8
        )
        content = response.choices[0].message.content
        # æ¸…æ´— JSON
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        result_list = json.loads(content.strip())
        if len(result_list) != len(batch_df):
            return batch_df['è§£è¯´æ–‡æœ¬'].tolist()
        return result_list
    except Exception as e:
        print(f"âš ï¸ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
        return batch_df['è§£è¯´æ–‡æœ¬'].tolist()

def main():
    if not MY_API_KEY:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
        return

    client = OpenAI(api_key=MY_API_KEY, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    
    # æ‰«æç”Ÿæˆçš„ final csv
    files = glob.glob(os.path.join("data", "**", "final_*_half.csv"), recursive=True)
    if not files:
        print("âŒ æœªæ‰¾åˆ° final_upper/lower_half.csvï¼Œè¯·å…ˆè¿è¡Œä¸»ç¨‹åºã€‚")
        return

    for filepath in files:
        print(f"ğŸ¨ æ­£åœ¨æ¶¦è‰²: {os.path.basename(filepath)} ...")
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            
            # åˆ†æ‰¹å¤„ç†
            BATCH_SIZE = 10
            batches = [df[i:i + BATCH_SIZE] for i in range(0, len(df), BATCH_SIZE)]
            styled_texts = []
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_batch = {executor.submit(process_batch, client, batch): i for i, batch in enumerate(batches)}
                
                results_map = {}
                for future in concurrent.futures.as_completed(future_to_batch):
                    batch_idx = future_to_batch[future]
                    try:
                        res = future.result()
                        results_map[batch_idx] = res
                        print(f"   âœ… æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} å®Œæˆ")
                    except Exception as e:
                        results_map[batch_idx] = batches[batch_idx]['è§£è¯´æ–‡æœ¬'].tolist()

            for i in range(len(batches)):
                styled_texts.extend(results_map.get(i, []))
                
            df['åŸè§£è¯´'] = df['è§£è¯´æ–‡æœ¬']
            df['è§£è¯´æ–‡æœ¬'] = styled_texts
            
            # è¿‡æ»¤ç©ºè¡Œ
            df_final = df[df['è§£è¯´æ–‡æœ¬'].astype(str).str.strip() != ""]
            
            new_path = filepath.replace(".csv", "_machine_style.csv")
            df_final.to_csv(new_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ‰ å®Œç¾ï¼è¾“å‡º: {new_path}")
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")

if __name__ == "__main__":
    main()